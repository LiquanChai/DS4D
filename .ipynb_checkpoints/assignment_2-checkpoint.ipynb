{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "%load_ext Cython\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "json_lists = ['2017-09-22:00:05:01'] # lists of file_name\n",
    "for j in json_lists:\n",
    "    with open('../twitter/'+j[:10]+'/'+j+'.json', 'r+') as r:\n",
    "        data = []\n",
    "        columns = ['id','text','geo']\n",
    "\n",
    "        for index, line in enumerate(r.readlines()):\n",
    "                data.append([])\n",
    "                d = json.loads(line)       \n",
    "                for i in columns:\n",
    "                    data[index].append(d[i])\n",
    "\n",
    "        json_ = dict()\n",
    "        json_['columns'] = columns\n",
    "        json_['index'] = [i for i in range(len(data))]\n",
    "        json_['data'] = data\n",
    "        with open('../cleaned_twitter/'+j[:10]+'/'+'c-'+j+'.json','w+') as w:\n",
    "            w.write(json.dumps(json_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_lists = ['2017-09-22:00:05:01']\n",
    "for j in json_lists:\n",
    "    df = pd.read_json('../cleaned_twitter/'+j[:10]+'/'+'c-'+j+'.json',orient='split')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['RT', ':', '#StopBiafraKillings', '#FreeBiafra', '#BiafraReferendum', '#UN', '#EU', 'https://t.co/YgwSvvgniN', 'https://t.co…']\n",
      "1 ['If', 'I', 'get', 'as', 'drunk', 'as', 'Tim', 'Martin', 'sounds', ',', 'will', '#Brexit', 'begin', 'to', 'make', 'sense', '?', '#bbctw']\n",
      "2 ['RT', ':', '#ScotRef', 'https://t.co/JSwYzGHdoB']\n",
      "3 ['RT', ':', 'With', 'you', 'all', 'the', 'way', '.', 'Do', 'not', 'give', 'in', 'to', 'their', 'bullying', '!', '#ScotsForCatalonia', '#indyref2', 'https://t.co/MMk1EzPgE2']\n",
      "4 ['Anti-LGBT', 'Laws', ',', 'Anti-Immigrant', 'Sentiments', 'May', 'Raise', '#HIV', 'Risk', 'for', '#Gay', 'Migrants', '-', 'via', 'https://t.co/U0QfSBBUB9', '#LGBT', '#MSM', '#Europe']\n",
      "5 ['#Brexit', '-', 'Can', '#Britian', 'pay', 'for', 'the', 'divorce', 'bill', '?', '-', 'Some', 'reports', 'say', 'no', 'https://t.co/MzoUzp3dO3']\n",
      "6 ['RT', ':', 'La', '#desobediència', 'al', 'carrer', 'perquè', 'els', 'carrers', 'són', 'nostres', '#referendum', '#1octubre', 'https://t.co/sPV1v1VQYn']\n",
      "7 ['oh', 'I', 'live', 'in', 'california', '&', 'everyone', 'around', 'me', 'is', 'aware', 'the', 'neo-nazi', 'liberal', 'commie-CRAT', 'CULT', 'in', 'our', 'back', 'yard', 'filled', '…', 'https://t.co/a1sJgNOqUG']\n",
      "8 ['Click', 'HERE', '▶', '️', 'https://t.co/dnLbnP9Iyz', '#EU', '#News', '#EuropeUnion', '➡', '️', 'Why', 'Rio', \"Ferdinand's\", 'boxing', 'career', 'will', 'be', 'just', 'like', 'Fr', '…', 'https://t.co/lrppcg3oEF']\n",
      "9 ['RT', ':', 'It', 'was', '45years', 'of', 'lies', 'and', 'deceit', 'by', 'you', 'lot', 'that', 'got', 'us', 'shackled', 'to', 'the', 'EU', 'against', 'the', 'will', 'of', 'the', '…']\n",
      "10 ['RT', ':', 'Molt', 'a', 'favor', 'de', 'la', 'llibertat', ',', 'de', 'la', 'democràcia', 'i', 'dels', 'drets', 'civils', '.', 'A', \"l'ampa\", 'les', 'famílies', 'participem', 'perquè', 'entre', 't', '…']\n",
      "11 ['RT', ':', 'Calling', 'for', 'the', 'immediate', 'release', 'of', 'all', 'innocent', 'prisoners', 'of', 'conscience', 'in', 'Iran', '#Taheri', '#Narges', '#Arash', '…']\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "# nltk.download()\n",
    "for index, line in enumerate(df['text']):\n",
    "#     print(line)\n",
    "#     tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
    "    t_token = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "    token = t_token.tokenize(line)\n",
    "    print(index,token)\n",
    "    if index>10:\n",
    "        break\n",
    "    else:pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
